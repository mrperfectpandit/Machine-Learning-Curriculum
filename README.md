# Machine-Learning-Curriculum

## Brief Introduction

A complete guide to learn Machine Learning for beginners.

This learning path is intended for everyone who wants to learn data science and build a career in data field especially Machine Learning or deep Learning Engg. In this guide, there is a corresponding link in each section that will help you to learn (at least to start) in each chapter.

## Table of Contents

<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#programming">Programming</a></li>
    <li>
      <a href="#machine-learning">Machine Learning</a>
      <ul>
        <li><a href="#supervised-learning">Supervised Learning</a></li>
        <li><a href="#unsupervised-learning">Unsupervised Learning</a></li>
      </ul>
    </li>
    <li>
      <a href="#evaluation-metrics">Evaluation Metrics</a>
      <ul>
        <li><a href="#supervised-learning-1">Supervised Learning</a></li>
        <li><a href="#unsupervised-learning-1">Unsupervised Learning</a></li>
      </ul>
    </li>
    <li><a href="#deep-learning">Deep Learning</a></li>
    
  </ol>
</details>

## Programming

1. [Basic Python](https://www.learnpython.org/)
2. [Object-oriented Programming](https://realpython.com/python3-object-oriented-programming/)

<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>



## Machine Learning

- ### Supervised Learning
1.  [Linear Regression](https://machinelearningmastery.com/linear-regression-for-machine-learning/)
2.  [Logistic Regression](https://machinelearningmastery.com/logistic-regression-for-machine-learning/)
3.  [Decision Tree](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/)
4.  [K-NN (K-Nearest Neighbors)](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)
5.  [Naive Bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)
6.  [Support Vector Machine](https://datascience.foundation/datatalk/basic-overview-of-svm-algorithm)
7.  [Random Forest](https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/)
8.  [XGBoost](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)
12. [TOOLBOX: Scikit Learn](https://scikit-learn.org/stable/)
13. [TOOLBOX: statsmodels](https://www.statsmodels.org/stable/index.html)
14. [CASE STUDY: House Pricing](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
15. [CASE STUDY: Titanic](https://www.kaggle.com/c/titanic)

<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>

- ### Unsupervised Learning

1. [K-Means Clustering](https://www.kdnuggets.com/2019/05/guide-k-means-clustering-algorithm.html)
2. [DBSCAN](https://www.analyticsvidhya.com/blog/2020/09/how-dbscan-clustering-works/)
3. [Hierarchical Clustering](https://www.kdnuggets.com/2019/09/hierarchical-clustering.html)

<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>

## Evaluation Metrics

- ### Supervised Learning

1. [Confusion Matrix](https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/)
2. [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)
3. [Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)
4. [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)
5. [F Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)
6. [ROC (Receiver Operating Characteristic)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)
7. [ROC AUC (Area Under Curve)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)
8. [MAE](https://www.statisticshowto.com/absolute-error/)
9. [MSE](https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/)


<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>

- ### Unsupervised Learning

1. [Elbow Method](<https://en.wikipedia.org/wiki/Elbow_method_(clustering)>)
2. [Silhouette Coefficient](https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c)

<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>

## Deep Learning

1. [Activation Functions](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)
2. [Linear Layer](https://medium.com/datathings/linear-layers-explained-in-a-simple-way-2319a9c2d1aa)
3. [CNN (Convolutional Neural Networks)](https://cs231n.github.io/)
4. [RNN (Recurrent Neural Networks)](https://builtin.com/data-science/recurrent-neural-networks-and-lstm)
5. [Optimization](https://d2l.ai/chapter_optimization/)
6. [Loss Functions / Objective Functions](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)
7. [Dropout](https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/deep_learning/dropout_layer)
8. [Batchnorm](https://www.baeldung.com/cs/batch-normalization-cnn)
9. [Learning Rate Scheduler](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1)
10. [TOOLBOX: Tensorflow](https://www.tensorflow.org/)
11. [TOOLBOX: Keras](https://keras.io)

<a href="#table-of-contents">ðŸ ¥ðŸ ¥ Back to Table of Contents ðŸ ¥ðŸ ¥</a>

## Capstone Project---




